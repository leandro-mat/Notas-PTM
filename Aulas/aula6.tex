\chapter[Aula 6]{Variáveis Aleatórias e Independência}
\chaptermark{}

\section{Variáveis Aleatórias}

\begin{definicao}[Variável Aleatória]\label{def-var-aleatoria}
Seja $(\Omega,\F)$ um espaço de medida e $\Lambda\in\F$.
Uma função $X:\Lambda\to\overline{\R}$ tal que para todo 
$B\in\mathscr{B}(\overline{\R})$ temos 
	\[
		\{\omega \in\Lambda: X(\omega)\in B\} 
		\in \Lambda\cap\F,
	\]
onde $\Lambda\cap \F$ denota a coleção de todos os 
subconjuntos de $\Omega$ da forma $\Lambda\cap F$
com $F\in\F$.
\end{definicao}

\begin{observacao}
Esta definição nesta generalidade é necessária por razões
lógicas em algumas aplicações, mas para a discussão das
propriedades básicas de variáveis aleatórias, podemos 
supor que $\Lambda =\Omega$.
\end{observacao}


\begin{exercicio}
Suponha que $\Lambda=\Omega$ na Definição \ref{def-var-aleatoria}.
Mostre que uma variável aleatória é uma função $\F$-mensurável
tomando valores em $\overline{\R}$ no sentido da seção anterior.  
\end{exercicio}

Seja $(\Omega,\F,\P)$ um espaço de probabilidade. 
Se $X:\Omega\to\overline{\R}$ é uma variável aleatória então vamos 
usar a notação
	\[
		\P(X\in B) \equiv \P(\{\omega\in\Omega: X(\omega)\in B\}).
	\]
Vamos usar a abreviação v.a. para nos referir a uma variável aleatória
e ao invés de escrever $X:\Omega\to \overline{\R}$ é uma 
v.a., vamos escrever simplesmente $X$ é uma v.a..
Quando $X(\Omega)\subset \R$ vamos dizer que $X$ é uma 
v.a. real.





\begin{proposicao}
	Se $X$ uma v.a. real em $(\Omega,\F,\P)$ então 
	$\mu:\F\to [0,1]$ dada por 
		\[
			\mu(B)\equiv \P(X^{-1}(B))=\P(X\in B)
		\]
	é uma medida de probabilidade em 
	$(\R,\mathscr{B}(\R))$.
\end{proposicao}

\begin{proof}
Claramente $\mu(B)\geq 0$ para todo $B\in \mathscr{B}(\R)$. 
Se $\{A_n\}$ é uma sequência de conjuntos 
mutuamente disjunta em $\mathscr{B}(\R)$ então 
$\{X^{-1}(A_n)\}$ é uma sequência mutuamente disjunta em $\Omega$, 
portanto 
\begin{align*}
	\mu \left( \bigcup_{n=1}^{\infty} A_n   \right)
	=
	\P \left( X^{-1}\left(\bigcup_{n=1}^{\infty} A_n \right) \right)
	=
	\P \left( \bigcup_{n=1}^{\infty} X^{-1}(A_n) \right)
	=&
	\sum_{n=1}^{\infty}\P(X^{-1}(A_n))
	\\
	=&
	\sum_{n=1}^{\infty}\mu(A_n)
\end{align*}
Já que $X^{-1}(\R)=\Omega$, temos que $\mu(\R)=1$ e
isto encerra a prova de que $\mu$ é uma medida de probabilidade.
\end{proof}

A medida de probabilidade $\mu$ induzida pela v.a. real $X$, 
definida na proposição acima, é frequentemente denotada por 
	\[
		\mu = \P\circ X^{-1}.
	\]
Neste caso, a função distribuição $F$ associada 
a medida $\mu$ é chamada 
{\bf função distribuição de $X$}, 
\index{Função!Distribuição de $X$}
mais especificamente 
	\[
		F(x) = \mu((-\infty,x]) = \P(X\leq x).
	\] 
Quando estivermos lidando com mais de uma v.a. usamos 
a notação $F_X$ para indicar que estamos falando da 
função distribuição de $X$.


\begin{teorema}
	Seja $(\Omega,\F)$ um espaço mensurável. 
	Se $X$ é uma v.a. real e $f:\R\to\R$ é uma 
	função mensurável (com respeito a $\sigma$-álgebra de Borel), 
	então $f(X)$ é uma v.a. real.
\end{teorema}

\begin{proof}
 Segue das propriedades elementares de composição de função que 
 $(f(X))^{-1}(A) = (f\circ X)^{-1}(A) = X^{-1}(f^{-1}(A))$.
 Logo 
 \[
 	(f\circ X)^{-1}(\mathscr{B}(\R))
 	=
 	X^{-1}(f^{-1}(\mathscr{B}(\R)))
 	=
 	X^{-1}(\mathscr{B}(\R))
 	\subset 
 	\F.
 \]
O que completa a demostração.
\end{proof}









\section{Independência}

Independência é uma propriedade básica de eventos e variáveis 
aleatórias em vários modelos de probabilidade. A definição deste
conceito é motivada pelo raciocínio intuitivo de que a ocorrência 
ou não de um evento não afeta nossa estimativa da probabilidade 
que um evento independente ocorra ou não. 
Apesar deste conceito ter um  apelo 
intuitivo é importante entender que independência em Teoria 
da Probabilidade é um conceito técnico com uma definição 
precisa e que deve ser verificada em cada modelo específico
que estiver sendo estudado.
 
Certamente existem exemplos de eventos dependentes que nossa 
intuição nos diz que eles devem ser dependentes e exemplos que 
nossa intuição diz que não devem ser independentes, mas que 
satisfazem a definição. Assim devemos recorrer sempre a definição 
para termos certeza sobre a independência de determinados eventos.  


\begin{definicao}
\label{def-2-eventos-independentes}
\index{Eventos!Independentes}
%
	Seja $(\Omega,\F,\P)$ um espaço de probabilidade fixado. 
	Os eventos $A$ e $B$ são ditos independentes  se 
		\[
			\P(A\cap B) = \P(A) \P(B).
		\]
%
\end{definicao}
%
%
%
%
%
\begin{definicao}{def-n-eventos-independentes}
Seja $(\Omega,\F,\P)$ um espaço de probabilidade fixado.
Dizemos que os eventos $A_1,\ldots,A_n$ são independentes
se 
	\[
		\P\left( \bigcap_{i\in I} A_i \right)
		=
		\prod_{i\in I} \P(A_i),
		\qquad
		\forall I\subset \{1,\ldots,n\}.
	\]	
\end{definicao}

Deve se observar que a condição de independência 
de eventos $A_1,\ldots,A_n$ envolve a verificação de 
	\[
		\sum_{k=2}^n \binom{n}{k} = 2^n-n-1
	\]
equações. 

Definimos em seguida, o conceito de independência de uma 
quantidade finita de coleções de subconjuntos de um espaço
de probabilidade. Em grande parte das aplicações vamos usar
este conceito com cada coleção sendo uma $sigma$-álgebra 
de conjuntos de $\Omega$. 


\begin{definicao}
\label{def-n-colecoes-independentes}
Sejam $(\Omega,\F,\P)$ um espaço de probabilidade fixado
e $\mathcal{C}_i\subset \F$,  $i=1,\ldots,n$ 
coleções de eventos. 
Dizemos que as coleções $\mathcal{C}_i$'s são independentes
se para qualquer escolha de $A_1,\ldots,A_n$, 
com $A_i\in \mathcal{C}_i$, $i=1,\ldots,n$, temos que 
os eventos $A_1,\ldots,A_n$ são eventos independentes.
\end{definicao}

Prosseguimos apresentando um critério bastante útil
para provar independência de uma 
quantidade finita de sub-$\sigma$-álgebras de $\F$.
Devido a sua importância nesta seção, vamos apresentá-lo
na forma de um teorema.

\begin{teorema}\label{teo-criterio-basico-independencia}
Seja $(\Omega,\F,\P)$ um espaço de probabilidade fixado.
Se $\mathcal{C}_i$ para $i=1,\ldots,n$ é uma 
coleção (não vazia) de {\bf eventos} tais que 
	\begin{enumerate}
		\item $\mathcal{C}_i	$ é um $\pi$-sistema;
		\item $\mathcal{C}_i,\ i=1,\ldots, n$ são independentes,
	\end{enumerate}	 	
então $\sigma(\mathcal{C}_1),\ldots, \sigma(\mathcal{C}_n)$ são 
independentes.
\end{teorema}




\begin{proof}
A prova deste teorema será feita por indução 
no número de coleções. 
Primeiro mostramos que a tese do teorema se 
verifica para o caso $n=2$. 
Fixe $A_2\in\mathcal{C}_2$ e defina
	\[
		\mathcal{L}
		=
		\{ A\in \F: \P(A\cap A_2) = \P(A)\P(A_2)\}.
	\]
Afirmamos que $\mathcal{L}$ é um $\lambda$-sistema.
De fato, primeiramente temos que $\Omega\in \mathcal{L}$ pois, 
$\P(\Omega\cap A_2)=\P(A_2)=\P(\Omega)\P(A_2)$.
A coleção $\mathcal{L}$ é fechada para complementação pois, 
para qualquer $A\in\mathcal{L}$, temos que
	\begin{align*}
	\P(A^c\cap A_2) 
	&=
	\P((\Omega\setminus A)\cap A_2)
	\\
	&=
	\P( A_2\setminus (A\cap A_2))
	\\
	&=
	\P( A_2) -\P(A\cap A_2)
	\\
	&=
	\P( A_2) -\P(A)\P(A_2)
	\\
	&=
	\P( A_2) (1-\P(A))
	\\
	&=
	\P(A_2)\P(A^c).
	\end{align*}
O que mostra que $A^c\in\mathcal{L}$. 
Para encerrar a prova da afimarção resta
mostrar que se $\{B_n\}$ uma coleção dois a dois disjunta 
em $\mathcal{L}$ então $\cup_{i=1}^{\infty} B_n\in\mathcal{L}$.
Este fato segue das seguintes igualdades
	\begin{align*}
	\P \left( A_2 \cap \bigcup_{n=1}^{\infty} B_n \right) 
	&=
	\P \left( \bigcup_{n=1}^{\infty} (A_2 \cap B_n) \right) 
	\\
	&=
	\sum_{n=1}^{\infty}\P \left( A_2 \cap B_n \right) 
	\\
	&=
	\sum_{n=1}^{\infty}\P(A_2)\P(B_n)
	\\
	&=
	\P(A_2)\sum_{n=1}^{\infty}\P(B_n)
	\\
	&=
	\P(A_2) \P \left( \bigcup_{n=1}^{\infty} B_n \right). 
	\end{align*}
%
%
%
Por hipótese $\mathcal{C}_1\subset \mathcal{L}$ 
e é um $\pi$-sistema.
Como mostramos que $\mathcal{L}$ é um 
$\lambda$-sistema podemos 
aplicar o Teorema de Dynkin para concluir que 
$\sigma(\mathcal{C}_1)\subset \mathcal{L}$.
Como $A_2$ é arbitrário em $\mathcal{C}_2$ 
temos mostrado neste momento que as coleções 
$\sigma(\mathcal{C}_1)$ e $\mathcal{C}_2$ 
são independentes.

Agora fixamos $A_1\in \sigma(\mathcal{C}_1)$ e
de maneira análoga definimos 
	\[
	\mathcal{K}=
	\{ A\in \F: \P(A\cap A_1) = \P(A)\P(A_1)\}
	\]
e verificamos que está coleção é um $\lambda$-sistema.
Como vimos acima, $\sigma(\mathcal{C}_1)$ e $\mathcal{C}_2$ 
são independentes logo $\mathcal{C}_2 \subset \mathcal{K}$.
Usando novamente o Teorema de Dynkin completamos a prova
do caso $n=2$. 

Claramente o passo de indução pode 
ser feito utilizando a técnica apresentada acima e 
assim o teorema está provado.
\end{proof}






\begin{definicao}[Coleções Independentes]
Sejam $(\Omega,\F,\P)$ um espaço de probabilidade e 
$I$ um conjunto de índices arbitrário.  
As coleções (de eventos) $\{\mathcal{C}_i\}_{i\in I}$
são independentes se para todo $J\subset I$ finito,
temos que as coleções $\{\mathcal{C}\}_{j\in J}$
são independentes.
\end{definicao}




\begin{corolario}
	Se $\{\mathcal{C}_i\}_{i\in I}$ é uma coleção 
	de $\pi$-sistemas não-vazios e independentes, 
	então $\{\sigma(\mathcal{C}_i)\}_{i\in I}$ são
	$\sigma$-álgebras independentes.
\end{corolario}









\section{Variáveis Aleatórias Independentes}

Nesta seção apresentamos um dos conceitos mais 
importantes deste curso que é o de v.a.'s independentes.
Também apresentamos nesta seção alguns critérios para
independência de v.a.'s.


\begin{definicao}[Variáveis Aleatórias Independentes]
\label{def-v.a.'s-independentes}
Sejam $(\Omega,\F,\P)$ um espaço de probabilidade fixado 
e $T$ um conjunto arbitrário de índices.
Uma coleção de variáveis aleatórias $\{X_t\}_{t\in T}$ 
é dita independente se a coleção de $\sigma$-álgebras 
$\{\sigma(X_t)\}_{t\in T}$ é independente.
\end{definicao}



Segundo nossa definição uma coleção de v.a.'s é 
independente se as $\sigma$-álgebras induzidas por
elas são independentes. Um caso particular interessante
é dado pela função indicadora de um evento. Neste 
caso, temos para todo evento $A$ que 
	\[
		\sigma(1_{A})=\{\emptyset, A,A^c,\Omega\}.
	\]
Assim as v.a.'s $1_{A_1},\ldots,1_{A_n}$ são 
independentes, se e somente se, $A_1,\ldots,A_n$ 
são eventos independentes. 

Apresentamos abaixo um critério para independência 
de v.a.'s em termos de suas funções distribuição.
Antes porém, vamos introduzir algumas notações.



Fixe um espaço de probabilidade $(\Omega,\F,\P)$,
um conjunto de índices $T$ e uma família de v.a.'s   
$\{X_t\}_{t\in T}$. Para cada $J\subset T$ finito
definimos  
	\[
		F_J(x_j, j\in J) 
		\equiv 
		\P \left(\, \bigcap_{j\in J} \{X_j\leq x_j\} \right).
	\]

\begin{teorema}
	Fixe um espaço de probabilidade $(\Omega,\F,\P)$ e
	um conjunto arbitrário de índices $T$.
	Uma família de v.a.'s $\{X_t\}_{t\in T}$ é independente
	se, e somente se, para todo subconjunto $J\subset T$ 
	finito temos que 
		\begin{equation}\label{eq-teo-fatorizacao-funcao-distribuicao}
			F_{J}(x_j,j\in J) = \prod_{j\in J}\P(X_j\leq x_j)
			\qquad
			\forall x_j\in \R.		
		\end{equation}
\end{teorema}


\begin{proof}
Para demonstrar o teorema é suficiente provar que 
para todo subconjunto {\bf finito} $J\subset T$ temos que 
as v.a.'s $\{X_j\}_{j\in J}$ são independentes
se, e somente se, vale a condição 
\eqref{eq-teo-fatorizacao-funcao-distribuicao}.

Para cada $j\in J$, defina 
	\[
		\mathcal{C}_j
		=
		\bigcup_{x\in\R} \{X_j\leq x\}.
	\]
É imediato verificar que $\mathcal{C}_j$	é 
um $\pi$-sistema e que 
$\sigma(\mathcal{C}_j)=\sigma(X_j)$.
Observe que a condição 
\eqref{eq-teo-fatorizacao-funcao-distribuicao}
diz que $\mathcal{C}_j$ é uma coleção de eventos
independentes e portanto segue do 
Teorema \ref{teo-criterio-basico-independencia}
que as $\sigma$-álgebras 
$\{ \sigma(\mathcal{C}_j)=\sigma(X_j)\}_{j\in J}$
são independentes. 	
\end{proof}





\begin{corolario}
	Uma coleção finita de v.a.'s $X_1,\ldots,X_n$
	em um espaço de probabilidade $(\Omega,\F,\P)$ é
	independente se, e somente se, 
		\[
			\P(X_1\leq x_1,\ldots, X_n\leq x_n)
			=
			\prod_{i=1}^n \P(X_i\leq x_i)
			\qquad
			\forall\ (x_1,\ldots,x_n)\in\R^n.
		\]
\end{corolario}


\begin{definicao}[Variável Aleatória Discreta]
\label{def-var-aleatoria-discreta}
\index{Variável Aleatória!Discreta}
Seja $(\Omega,\F,\P)$ um espaço de probabilidade.
Dizemos que uma v.a. $X$ é discreta se $X(\Omega)$ 
é um subconjunto enumerável de $\R$.
\end{definicao}


\begin{corolario}\label{cor-criterio-independencia-v.a.-discreta}
Seja $(\Omega,\F,\P)$ um espaço de probabilidade.
Suponha que $X_1,\ldots,X_n$ seja uma coleção de 
v.a.'s {\bf discretas} com conjunto imagem comum igual 
a $\mathcal{R}\subset \R$. Sob estas condições 
a coleção $X_1,\ldots,X_n$ é independente 
se, e somente se,  
	 	\begin{equation}\label{eq-fatorizacao-func-distribuicao-v.a.-discretas}
			\P(X_1= x_1,\ldots, X_n=x_n)
			=
			\prod_{i=1}^n \P(X_i = x_i)
			\qquad
			\forall\ (x_1,\ldots,x_n)\in\mathcal{R}^n.
		\end{equation}
\end{corolario}


\begin{proof}
Supondo que $X_1,\ldots,X_n$ é uma família de v.a.'s independentes
temos que $\sigma(X_i), i=1,\ldots,n$ é uma coleção
de $\sigma$-álgebras independentes.
Já que $\{X_i=x_i\}\in \sigma(X_i)$ temos que 
$\{X_i=x_i\}, i=1,\ldots, n$ são eventos independentes e assim a 
condição \ref{eq-fatorizacao-func-distribuicao-v.a.-discretas}
é satisfeita.

Por questão de simplicidade vamos 
mostrar a recíproca para o caso $n=2$. 
A prova para o caso geral é obtida
de maneira análoga. 
%
Sejam $(z_1,z_2)$ e $(x_1,x_2)$ vetores em $\R^2$. 
Considere a seguinte relação de ordem parcial em $\R^2$, 
$(z_1,z_2)\preceq (x_1,x_2)$ se $z_1\leq x_1$ e $z_2\leq x_2$.
Usando a condição \ref{eq-fatorizacao-func-distribuicao-v.a.-discretas}
temos para qualquer $(x_1,x_2)\in\R^2$ a seguintes igualdades:
\begin{align*}
\P(X_1\leq x_1,\, X_2\leq x_2)
&=
	\sum_{
		\substack {(z_1,z_2)\preceq (x_1,x_2) 
					\\ (z_1,z_2)\in\mathcal{R}^2 }  
	} 
	\P(X_1= z_1,\, X_2= z_2)
\\[0.3cm]
&=
	\sum_{
		\substack {(z_1,z_2)\preceq (x_1,x_2) 
					\\ (z_1,z_2)\in\mathcal{R}^2 }  
	} 
	\P(X_1= z_1) \P(X_2= z_2)
\\[0.3cm]
&=
	\sum_{\substack {z_1\leq x_1 \\ z_1\in\mathcal{R} } } 
	\sum_{\substack {z_2\leq x_2 \\ z_2\in\mathcal{R} } }
	\P(X_1= z_1) \P(X_2= z_2)
\\[0.3cm]
&=
	\sum_{\substack {z_1\leq x_1 \\ z_1\in\mathcal{R} } } 
	\P(X_1= z_1)
	\sum_{\substack {z_2\leq x_2 \\ z_2\in\mathcal{R} } }
	\P(X_2= z_2)
\\[0.3cm]
&=
	\P(X_1\leq x_1)\P(X_2\leq x_2).
\end{align*}
Usando o corolário anterior segue que $X_1$ e $X_2$
são independentes.
\end{proof}











\section{O Teorema de Renyi}\label{sec-teo-Renyi}

O objetivo desta seção é apresentar um exemplo 
interessante onde aparecem variáveis aleatórias 
independentes bem como alguns cálculos explícitos de eventos 
associados a elas. Este exemplo é conhecido como 
Teorema de Renyi e antes de passarmos à sua prova
vamos provar um lema sobre v.a.'s iid com distribuição 
contínua, em seguida introduzimos algumas notações e 
depois enunciamos e provamos o Teorema de Renyi




\begin{lema}\label{lema-P(X_i-dif-X_j)=1}
Sejam $(\Omega,\F,\P)$ um espaço de probabilidade e 
$\{X_n\}$ uma sequência de variáveis aleatórias
iid com função distribuição {\bf contínua} comum 
dada por $F$. Então para todo $i\neq j$ temos que
	\[
		\P(X_i=X_j)=0.
	\]
\end{lema}


\begin{proof}
Para fixar as ideias vamos provar o lema para 
o caso $i=1$ e $j=2$, isto é, $\P(X_1=X_2)=0$.
Primeiro observe que temos para todo $n\in\N$ 
a seguinte continência de conjuntos 
	\[
	\{X_1=X_2\}
	\subset
	\bigcup_{k=-\infty}^{\infty}
	\left\{
		\frac{k-1}{2^n}<X_1\leq \frac{k}{2^n}
	\right\}
	\cap
	\left\{
		\frac{k-1}{2^n}<X_2\leq \frac{k}{2^n}
	\right\}
	\]
Usando a monotonicidade e subaditividade da medida
de probabilidade $\P$ e a independência de 
$X_1$ e $X_2$ temos a seguinte estimativa
	\begin{align*}
	\P(X_1=X_2)
	&\leq
	\sum_{k=-\infty}^{\infty}
	\P \left(
		\left\{
			\frac{k-1}{2^n}<X_1\leq \frac{k}{2^n}
		\right\}
		\cap
		\left\{
			\frac{k-1}{2^n}<X_2\leq \frac{k}{2^n}
		\right\}
	\right)
	\\[0.4cm]
	&=
	\sum_{k=-\infty}^{\infty}
	\P \left(
		\left\{
			\frac{k-1}{2^n}<X_1\leq \frac{k}{2^n}
		\right\}
	\right)^2.
	\end{align*}
%
%
%
Como $X_1$ tem função distribuição $F$ o lado 
direito da desigualdade acima é igual 
	\begin{align*}
	\sum_{k=-\infty}^{\infty}
	\left(
		F\left(\frac{k}{2^n}\right)
		-
		F\left(\frac{k-1}{2^n}\right)
	\right)^2
	\end{align*}
que por sua vez é cotado superiormente por 
	\begin{align*}
	\sup_{k\in\Z}
		\left(
			F\left(\frac{k}{2^n}\right)
			-
			F\left(\frac{k-1}{2^n}\right)
		\right)
	\sum_{k=-\infty}^{\infty}
	\left(
		F\left(\frac{k}{2^n}\right)
		-
		F\left(\frac{k-1}{2^n}\right)
	\right)	
	\end{align*}
Usando um argumento telescópico e que $F$ é uma 
função de distribuição podemos verificar que a soma
acima é majorada por 1. Juntando todas estas estimativas
temos
	\begin{align*}
	\P(X_1=X_2)
	\leq 
	\sup_{k\in\Z}
		\left(
			F\left(\frac{k}{2^n}\right)
			-
			F\left(\frac{k-1}{2^n}\right)
		\right).
	\end{align*}
 Usando novamente que $F$ é uma função distribuição podemos
 afirmar que $F$ é uniformemente contínua em $\R$, daí dado 
 $\varepsilon>0$ para todo $n\geq n_0(\varepsilon)$ temos que 
	\[
			F\left(\frac{k}{2^n}\right)
			-
			F\left(\frac{k-1}{2^n}\right)
			< 
			\varepsilon
			\qquad
			\forall k\in\Z
	\]  
e portanto segue que $\P(X_1=X_2)< \varepsilon$. 
Como $\varepsilon>0$ é arbitrário, 
o lema está provado.
\end{proof}



\bigskip

Considere uma sequência $\{X_n\}$ de v.a.'s iid 
com distribuição contínua $F$ em um espaço de probabilidade
$(\Omega,\F,\P)$. 
Dizemos que há um ``empate'' entre estas v.a.'s  se
para algum $\omega\in\Omega$ temos que
$X_i(\omega)=X_j(\omega)$ para todo $i,j\in\N$.
Vamos usar a notação simplificada 
	\[
		\{ \text{Empate} \}
		=
		\bigcup_{i\neq j} \{X_i=X_j\}	
	\]
Pelo lema anterior temos que
$\P(\{\text{Empate}\})=0$.
Vamos dizer que $X_n$ é um recorde (entre $X_1,\ldots,X_{n-1}$)
se 
	\[ 
	X_n>\max\{X_1,\ldots,X_{n-1}\}.
	\]
Para simplificar a notação vamos denotar por 
$A_n = \{X_n \ \text{é um recorde}\ \}$.
O Teorema de Renyi entre outras coisas afirma que
os eventos $\{A_n\}$ são independentes e também que 
	\[
		\P(A_j)=\frac{1}{j}
		\qquad 
		\forall\ j\geq 2.
	\]
Isto é na verdade um caso particular de ``{\it ranks}''
relativos de $X_n$ que é v.a.'s definida da seguinte maneira:
	\[
		R_n = \sum_{i=1}^n 1_{\{X_j\geq X_n\}}.
	\]
Note que $R_n=1$ se, e somente se, $X_n$ é um recorde.
Quando $R_n=2$ temos que $X_n$ é o segundo maior 
valor entre $X_1,\ldots,X_n$ e assim por diante.





%%% TEOREMA DE RENYI



\begin{teorema}
	Seja $(\Omega,\F,\P)$ um espaço de probabilidade. 
	Suponha que $\{X_n\}$ seja uma sequência iid 
	com distribuição contínua $F$. 
	\begin{itemize}
		\item[a)] 
		A sequência de v.a's $\{R_n\}$ é independente e
			\[
				\P(R_n=k) = \frac{1}{n},
				\qquad \forall n\geq 2 \ \text{e}\ 
				k=1,\ldots,n.
			\]
		
		\item[b)]
		A sequência de eventos $\{A_n\}$ é 
		independente e 
			\[
				\P(A_n) = \frac{1}{n},\qquad \forall n\geq 2.
			\]
	\end{itemize}
\end{teorema} 







\begin{proof}
	Observe que o item $b)$ é uma consequência imediata do 
	item $a)$ já que $A_n=\{R_n=1\}$. 
	
	Seguimos com a prova do item a). 
	Usando o Lema \ref{lema-P(X_i-dif-X_j)=1}	
	temos, com probabilidade um, que 
	existem exatamente $n!$ ordenamentos das v.a.'s 
	$X_1,\ldots,X_n$, isto é, se 	$\omega\in\Omega$ é
	escolhido no conjunto de probabilidade um dado pelo 
	Lema \ref{lema-P(X_i-dif-X_j)=1} então  
    uma das $n!$ alternativas ocorrem 
    $X_{\sigma(1)}(\omega)<X_{\sigma(2)}(\omega)<\ldots <X_{\sigma(n)}(\omega)$,
    onde $\sigma$ é uma permutação arbitrária do conjunto $\{1,\ldots,n\}$.
	

\begin{exercicio}
	Sob as hipóteses do teorema prove que
		\[
			\P(X_{\sigma(1)}<X_{\sigma(2)}<\ldots <X_{\sigma(n)})=\frac{1}{n!}
			\qquad \forall \sigma\in \mathbb{S}_n,
		\]
onde $\mathbb{S}_n$ é o grupo de permutações de $n$ símbolos.
\end{exercicio}


Observamos que cada realização de 
$R_1,\ldots, R_n$ determina uma ordenação,
por exemplo, se $n=3$ e $R_1(\omega)=1,\ R_2(\omega)=1$
e $R_3(\omega)=1$ temos que 
$X_1(\omega)<X_2(\omega)<X_3(\omega)$.
Se $R_1(\omega)=1,\ R_2(\omega)=2$ e $R_3(\omega)=3$,
então temos que $X_3(\omega)<X_2(\omega)<X_1(\omega)$.
Por causa da correspondência citada acima para todo
$r_i=1,\ldots,i$, com $i=1,\ldots,n$ temos 
	\[
		\P(R_1=r_1,\ldots, R_n=r_n)=\frac{1}{n!}.
	\]
Note que 
	\begin{align*}
	\P(R_n=r_n)
	&=
	\sum_{r_1,\ldots,r_{n-1}} \P(R_1=r_1,\ldots,R_n=r_n) 
	\\
	&=
	\sum_{r_1,\ldots, r_{n-1}} \frac{1}{n!}.
	\end{align*}
Já que cada $i=1,\ldots,n$ temos $1\leq r_i\leq i$,
segue que a soma acima possui exatamente 
$1\cdot 2\cdot 3\cdot\ldots\cdot n-1=(n-1)!$
termos. Logo  
	\[
		\P(R_n=r_n)=\frac{(n-1)!}{n!}=\frac{1}{n}
		\qquad
		n=1,2,\ldots
	\]
Esta igualdade juntamente com o Corolário 
\ref{cor-criterio-independencia-v.a.-discreta}
implica que as variáveis aleatórias $\{R_i\}$
são independentes, pois para todo $n\in\N$ temos
	\begin{align*}
		\P(R_1=r_1,\ldots R_n=r_n)
		&=\frac{1}{n!}
		\\
		&=\P(R_1=r_1)\P(R_2=r_2)\P(R_3=r_3)\ldots\P(R_n=r_n).
	\end{align*}
\end{proof}



\section{Expansões Diádicas de Números Aleatórios Distribuídos Uniformemente}



\begin{center}
	{\red Em andamento.}
\end{center}


